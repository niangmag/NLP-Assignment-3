# -*- coding: utf-8 -*-
"""streamlit_transfomers_app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M1exYJNHDMR4aCJ2kKCfwDzPUWt48tPN
"""

import streamlit as st
from transformers import pipeline

# Chargement du modÃ¨le GPT-2 depuis Hugging Face
@st.cache_resource
def load_model():
    return pipeline("text-generation", model="gpt2")

model = load_model()

# Interface utilisateur
st.title("LLM Chatbot (Hugging Face - GPT-2)")

user_input = st.text_input("Posez votre question ici :")

if user_input:
    st.write("ðŸ¤– RÃ©ponse :")
    output = model(user_input, max_length=100, do_sample=True, top_k=50, temperature=0.7)
    st.write(output[0]['generated_text'])