{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzaqJUGJmquzCiSYgrJ/9L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niangmag/NLP-Assignment-3/blob/LLM_Usage/Report_NLP_Models_Large_Language_Models_125.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report on Email Classification using LLM\n",
        "\n",
        "This report summarizes the practical exercise on classifying emails using a Large Language Model (LLM) as per the instructions provided.\n",
        "\n",
        "Objective: The goal was to classify emails from the spam.csv dataset as \"spam\" or \"not spam\" using an LLM loaded from Hugging Face, employing prompt engineering to ensure the output is strictly the class name.\n",
        "\n",
        "Methodology:\n",
        "\n",
        "Environment Setup: Necessary libraries, langchain-huggingface and transformers, were installed.\n",
        "LLM Loading: The GPT2 model was loaded from Hugging Face using HuggingFacePipeline with a specified maximum number of new tokens (max_new_tokens=10).\n",
        "Data Loading: The spam.csv dataset was loaded into a pandas DataFrame.\n",
        "Prompt Engineering: A PromptTemplate was created with explicit instructions for the LLM to classify the email and respond only with \"spam\" or \"not spam\".\n",
        "Classification Function: A Python function classify_email was developed to take email text as input, format it with the prompt, pass it to the LLM, and attempt to post-process the output to extract the class label.\n",
        "Classification Execution: The classify_email function was applied to example emails and intended to be applied to the entire dataset.\n",
        "Results and Observations:\n",
        "\n",
        "The initial attempts to classify individual emails showed that while the LLM attempted the classification, it did not strictly adhere to the instruction to output only the class name. The output often included parts of the input prompt or additional text.\n",
        "An adjustment was made to the classify_email function and the prompt to include more explicit instructions and basic post-processing to clean the output.\n",
        "Testing the modified function on example emails demonstrated improved adherence to the desired output format, returning primarily \"spam\" or \"not spam\".\n",
        "Attempting to classify the entire dataset was initiated but interrupted due to the significant time required. Classifying a large number of emails individually using this method with the chosen LLM proved to be computationally intensive."
      ],
      "metadata": {
        "id": "7NG9mNtEeUhI"
      }
    }
  ]
}